
In competitive situations, agents may take actions to achieve their goals that unwittingly facilitate an opponent's goals. 
We consider a domain where three agents operate: (1) a human user, (2) an attacker (human or a software agent)  and (3) an observer (a software agent). The user and the attacker compete to achieve different goals. When there is a disparity in the domain knowledge they possess, the attacker may use the user's unfamiliarity with the domain to further its own goal and defeat the user. We present a design for the observer who supports the user by intervening upon recognizing risky actions. We formalize the online plan intervention problem and propose a solution that uses a classifier to identify intervention points. We train a classifier using domain-independent features extracted from the observer's decision space to assess the ``criticality'' of the current state. The trained model is then used in an online setting on IPC benchmarks and Rush Hour game to predict intervention. Our evaluation shows that the classifier identifies actions that warrant intervention with good accuracy compared to state-of-the-art plan/goal recognition approaches.


%We formalize the online plan intervention problem and propose a solution that uses a classifier to identify intervention points in situations where agents unwittingly facilitate an opponent's goal. We trained a classifier using domain-independent features extracted from the observer's decision space to evaluate the ``criticality'' of the current state. The trained model is then used in an online setting on IPC benchmarks and Rush Hour game to identify observations that warrant intervention. We further augment the observer with the ability to explain intervention using a causal model. Our evaluation shows that the classifier identifies actions that warrant intervention with good accuracy compared to state-of-the-art plan/goal recognition approaches.

%We model the decision space of the intervening agent as an intervention graph, which identifies states that are reachable at different depths starting from the current state.  We then train a classifier that evaluates ``criticality'' of the current state using a domain-independent features extracted from the graph that include: the risk of reaching an undesirable state, the desirability of the observed action to support the user to achieving his goal, the distances to undesirable and desirable goal states, and the effect of current observation to activate/deactivate landmarks in the domain. The trained classifier is then used in an online setting on IPC benchmarks to predict intervention.  Our evaluation shows that the classifier identifies actions that warrant intervention with good accuracy. Further, we identify that delaying intervention until certain landmarks become active is a reasonable choice that does not compromise accuracy.  Our contributions lay a foundation for further work in the area of deciding when to intervene.
